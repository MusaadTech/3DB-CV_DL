{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 3 = INFO, WARNING, and ERROR\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "NUMBER_CLASSES = 10\n",
    "activity_map = {'c0': 'Safe driving',\n",
    "                'c1': 'Texting - right',\n",
    "                'c2': 'Talking on the phone - right',\n",
    "                'c3': 'Texting - left',\n",
    "                'c4': 'Talking on the phone - left',\n",
    "                'c5': 'Operating the radio',\n",
    "                'c6': 'Drinking',\n",
    "                'c7': 'Reaching behind',\n",
    "                'c8': 'Hair and makeup',\n",
    "                'c9': 'Talking to passenger'}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_cv2_image(path, img_rows, img_cols, color_type=3):\n",
    "    \"\"\"\n",
    "    Function that return an opencv image from the path and the right number of dimension\n",
    "    \"\"\"\n",
    "    if color_type == 1:  # Loading as Grayscale image\n",
    "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    elif color_type == 3:  # Loading as color image\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    img = cv2.resize(img, (img_rows, img_cols))  # Reduce size\n",
    "    return img\n",
    "\n",
    "\n",
    "# Loading Training dataset\n",
    "def load_train(img_rows, img_cols, color_type=3):\n",
    "    \"\"\"\n",
    "    Return train images and train labels from the original path\n",
    "    \"\"\"\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # Loop over the training folder\n",
    "    for classed in tqdm(range(NUMBER_CLASSES)):\n",
    "        print('Loading directory c{}'.format(classed))\n",
    "        files = glob(os.path.join('D:/Kaggle/imgs/train/c' + str(classed), '*.jpg'))\n",
    "        for file in files:\n",
    "            img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "            train_images.append(img)\n",
    "            train_labels.append(classed)\n",
    "    return train_images, train_labels\n",
    "\n",
    "\n",
    "def read_and_normalize_train_data(img_rows, img_cols, color_type):\n",
    "    \"\"\"\n",
    "    Load + categorical + split\n",
    "    \"\"\"\n",
    "    X, labels = load_train(img_rows, img_cols, color_type)\n",
    "    y = np_utils.to_categorical(labels, 10)  # categorical train label\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                        random_state=42)  # split into train and test\n",
    "    x_train = np.array(x_train, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "    x_test = np.array(x_test, dtype=np.uint8).reshape(-1, img_rows, img_cols, color_type)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Loading validation dataset\n",
    "def load_test(size=200000, img_rows=64, img_cols=64, color_type=3):\n",
    "    \"\"\"\n",
    "    Same as above but for validation dataset\n",
    "    \"\"\"\n",
    "    path = os.path.join('D:/Kaggle/imgs/test', '*.jpg')\n",
    "    files = sorted(glob(path))\n",
    "    X_test, X_test_id = [], []\n",
    "    total = 0\n",
    "    files_size = len(files)\n",
    "    for file in tqdm(files):\n",
    "        if total >= size or total >= files_size:\n",
    "            break\n",
    "        file_base = os.path.basename(file)\n",
    "        img = get_cv2_image(file, img_rows, img_cols, color_type)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(file_base)\n",
    "        total += 1\n",
    "    return X_test, X_test_id\n",
    "\n",
    "\n",
    "def read_and_normalize_sampled_test_data(size, img_rows, img_cols, color_type=3):\n",
    "    test_data, test_ids = load_test(size, img_rows, img_cols, color_type)\n",
    "    test_data = np.array(test_data, dtype=np.uint8)\n",
    "    test_data = test_data.reshape(-1, img_rows, img_cols, color_type)\n",
    "    return test_data, test_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:10<01:35, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:18<01:14,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:27<01:01,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:35<00:51,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:44<00:43,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:52<00:34,  8.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [01:01<00:25,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:08<00:16,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:16<00:08,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading directory c9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:28<00:00,  8.89s/it]\n",
      "  0%|          | 200/79726 [00:00<05:31, 240.20it/s]\n"
     ]
    }
   ],
   "source": [
    "img_rows = 64  # dimension of images\n",
    "img_cols = 64\n",
    "color_type = 1  # grey\n",
    "nb_test_samples = 200\n",
    "\n",
    "# loading train images\n",
    "x_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)\n",
    "\n",
    "# loading validation images\n",
    "test_files, test_targets = read_and_normalize_sampled_test_data(nb_test_samples, img_rows, img_cols, color_type)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Number of batch size and epochs\n",
    "batch_size = 40\n",
    "nb_epoch = 6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "models_dir = \"saved_models\"\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Proposed selected model.\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    ## CNN 1\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_rows, img_cols, color_type)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    ## CNN 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    ## CNN 3\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(BatchNormalization(axis=3))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    ## Output\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "model = create_model()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "449/449 [==============================] - 19s 27ms/step - loss: 1.2152 - accuracy: 0.6077 - val_loss: 0.3711 - val_accuracy: 0.8948\n",
      "Epoch 2/6\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.3278 - accuracy: 0.8958 - val_loss: 0.1037 - val_accuracy: 0.9686\n",
      "Epoch 3/6\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.2028 - accuracy: 0.9377 - val_loss: 0.0746 - val_accuracy: 0.9799\n",
      "Epoch 4/6\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.1553 - accuracy: 0.9540 - val_loss: 0.0701 - val_accuracy: 0.9815\n",
      "Epoch 5/6\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.1219 - accuracy: 0.9655 - val_loss: 0.0944 - val_accuracy: 0.9726\n",
      "Epoch 6/6\n",
      "449/449 [==============================] - 11s 25ms/step - loss: 0.1111 - accuracy: 0.9675 - val_loss: 0.0702 - val_accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=nb_epoch, batch_size=batch_size, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Second proposed model\n",
    "def create_model_2():\n",
    "    model_2 = Sequential()\n",
    "\n",
    "    ## CNN 1\n",
    "    model_2.add(Conv2D(32, 3, 3, padding='same', input_shape=(img_rows, img_cols, color_type)))\n",
    "    model_2.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model_2.add(Dropout(0.5))\n",
    "\n",
    "    ## CNN 2\n",
    "    model_2.add(Conv2D(64, 3, 3, padding='same'))\n",
    "    model_2.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model_2.add(Dropout(0.5))\n",
    "\n",
    "    ## CNN 3\n",
    "    model_2.add(Conv2D(128, 3, 3, padding='same'))\n",
    "    model_2.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model_2.add(Dropout(0.5))\n",
    "\n",
    "    ## Output\n",
    "    model_2.add(Flatten())\n",
    "    model_2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model_2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model_2 = create_model_2()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "449/449 [==============================] - 4s 8ms/step - loss: 6.6706 - accuracy: 0.1445 - val_loss: 1.9745 - val_accuracy: 0.2910\n",
      "Epoch 2/6\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 2.1483 - accuracy: 0.2642 - val_loss: 1.4473 - val_accuracy: 0.5766\n",
      "Epoch 3/6\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 1.7167 - accuracy: 0.3994 - val_loss: 1.0381 - val_accuracy: 0.7407\n",
      "Epoch 4/6\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 1.5018 - accuracy: 0.4782 - val_loss: 0.8368 - val_accuracy: 0.7891\n",
      "Epoch 5/6\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 1.3800 - accuracy: 0.5248 - val_loss: 0.7285 - val_accuracy: 0.8305\n",
      "Epoch 6/6\n",
      "449/449 [==============================] - 3s 7ms/step - loss: 1.3070 - accuracy: 0.5492 - val_loss: 0.6552 - val_accuracy: 0.8352\n"
     ]
    }
   ],
   "source": [
    "history_2 = model_2.fit(x_train, y_train,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=nb_epoch, batch_size=batch_size, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Third proposed model\n",
    "def create_model_3():\n",
    "    model_3 = Sequential()\n",
    "\n",
    "    ## CNN 1\n",
    "    model_3.add(Conv2D(64, (3, 3), activation='relu', input_shape=(img_rows, img_cols, color_type)))\n",
    "    model_3.add(BatchNormalization())\n",
    "    model_3.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model_3.add(BatchNormalization(axis=3))\n",
    "    model_3.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model_3.add(Dropout(0.3))\n",
    "\n",
    "    ## CNN 2\n",
    "    model_3.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model_3.add(BatchNormalization())\n",
    "    model_3.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model_3.add(BatchNormalization(axis=3))\n",
    "    model_3.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model_3.add(Dropout(0.5))\n",
    "\n",
    "    ## Output\n",
    "    model_3.add(Flatten())\n",
    "    model_3.add(Dense(512, activation='relu'))\n",
    "    model_3.add(BatchNormalization())\n",
    "    model_3.add(Dropout(0.5))\n",
    "    model_3.add(Dense(128, activation='relu'))\n",
    "    model_3.add(Dropout(0.25))\n",
    "    model_3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model_3.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model_3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "model_3 = create_model_3()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "449/449 [==============================] - 17s 35ms/step - loss: 0.8152 - accuracy: 0.7375 - val_loss: 0.2422 - val_accuracy: 0.9264\n",
      "Epoch 2/6\n",
      "449/449 [==============================] - 15s 34ms/step - loss: 0.1972 - accuracy: 0.9385 - val_loss: 0.4120 - val_accuracy: 0.8595\n",
      "Epoch 3/6\n",
      "449/449 [==============================] - 15s 33ms/step - loss: 0.1318 - accuracy: 0.9608 - val_loss: 0.3597 - val_accuracy: 0.9110\n",
      "Epoch 4/6\n",
      "449/449 [==============================] - 16s 35ms/step - loss: 0.0927 - accuracy: 0.9718 - val_loss: 0.1255 - val_accuracy: 0.9643\n",
      "Epoch 5/6\n",
      "449/449 [==============================] - 15s 34ms/step - loss: 0.0845 - accuracy: 0.9747 - val_loss: 0.0458 - val_accuracy: 0.9857\n",
      "Epoch 6/6\n",
      "449/449 [==============================] - 15s 34ms/step - loss: 0.0657 - accuracy: 0.9795 - val_loss: 0.1085 - val_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "history_3 = model_3.fit(x_train, y_train,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=nb_epoch, batch_size=batch_size, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 5ms/step - loss: 0.0702 - accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "score1 = model.evaluate(x_test, y_test, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.8352\n"
     ]
    }
   ],
   "source": [
    "score2 = model_2.evaluate(x_test, y_test, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 0.1085 - accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "score3 = model_3.evaluate(x_test, y_test, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/selected_model/Model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"saved_models/selected_model/Model_1\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/compared_model/Model_2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_2.save(\"saved_models/compared_model/Model_2\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/compared_model/Model_3\\assets\n"
     ]
    }
   ],
   "source": [
    "model_3.save(\"saved_models/compared_model/Model_3\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}